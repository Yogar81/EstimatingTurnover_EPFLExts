{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Turnover in Retail Trade\n",
    "\n",
    "### Capstone Project by Christian Furger "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning - Data Cleaning and Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to estimate turnover for a given enterprise/month (e.g. for enterprise X and 2017-06) based on different features:\n",
    "* Target: TOV (monthly turnover per enterprise)\n",
    "* Features: VAT, employment, TOV_lag1, TOV_lag2, TOV_lag12, Activity, Size, Sample_ID, Profiling, Group, Area (Canton), Language\n",
    "\n",
    "Because of the coronavirus pandemic, which had a huge impact on retail sales, the models will be estimated once with data including 2020, once ending december 2019.\n",
    "\n",
    "The data will be split randomly into train/test sets. This means that the entries of the test set will be dispersed over the whole time period. The goal is not to predict turnover in the future, but estimate it for a period for which there are already answers from other enterprises available.\n",
    "\n",
    "##### What models are you planning to use and why?\n",
    "This project can be seen as multiple regression problem. It can also be seen as a classification/clustering problem, where we try to group the enterprises and use the nearest neighbor or the mean of the cluster to estimate the missing turnover data. Therefore, I plan to use the following models:\n",
    "* Ridge regression\n",
    "* k-NN regression\n",
    "* RandomForest regression\n",
    "* Clustering (k-Means)\n",
    "\n",
    "Exept for the RandomForest approach, I will standardize the data. To find the optimal parameters, I'll use hyperparameter tuning.\n",
    "\n",
    "For each model, there is a separate jupyter notebook. In a final notebook, all models are compared with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning and Feature Encoding <a name=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143933, 35)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Dataset\n",
    "resp_data = pd.read_csv('resp_data_prep.csv', index_col = ('OID', 'Date'), dtype = {'Stratum_Noga' : object, 'Noga_Enterprise' : object, 'Hist_Limit' : object})\n",
    "resp_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>KT</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>Lang</th>\n",
       "      <th>Stratum_Noga</th>\n",
       "      <th>Empl_Enterprise</th>\n",
       "      <th>Stratum_Size</th>\n",
       "      <th>FTE_Enterprise</th>\n",
       "      <th>Profiling</th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Noga_Enterprise</th>\n",
       "      <th>...</th>\n",
       "      <th>Split</th>\n",
       "      <th>SentFor</th>\n",
       "      <th>TOV</th>\n",
       "      <th>nb_modif</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Lockdown</th>\n",
       "      <th>TOV_lag1</th>\n",
       "      <th>TOV_lag2</th>\n",
       "      <th>TOV_lag12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OID</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1005620</th>\n",
       "      <th>2015-01</th>\n",
       "      <td>GE</td>\n",
       "      <td>1212</td>\n",
       "      <td>2</td>\n",
       "      <td>477</td>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.969999</td>\n",
       "      <td>0</td>\n",
       "      <td>Q3</td>\n",
       "      <td>4773</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02</th>\n",
       "      <td>GE</td>\n",
       "      <td>1212</td>\n",
       "      <td>2</td>\n",
       "      <td>477</td>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.969999</td>\n",
       "      <td>0</td>\n",
       "      <td>Q3</td>\n",
       "      <td>4773</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>554</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03</th>\n",
       "      <td>GE</td>\n",
       "      <td>1212</td>\n",
       "      <td>2</td>\n",
       "      <td>477</td>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.969999</td>\n",
       "      <td>0</td>\n",
       "      <td>Q3</td>\n",
       "      <td>4773</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>629</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04</th>\n",
       "      <td>GE</td>\n",
       "      <td>1212</td>\n",
       "      <td>2</td>\n",
       "      <td>477</td>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.969999</td>\n",
       "      <td>0</td>\n",
       "      <td>Q3</td>\n",
       "      <td>4773</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>629.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05</th>\n",
       "      <td>GE</td>\n",
       "      <td>1212</td>\n",
       "      <td>2</td>\n",
       "      <td>477</td>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.969999</td>\n",
       "      <td>0</td>\n",
       "      <td>Q3</td>\n",
       "      <td>4773</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>569</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>629.0</td>\n",
       "      <td>582.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 KT   ZIP  Lang Stratum_Noga  Empl_Enterprise  Stratum_Size  \\\n",
       "OID     Date                                                                  \n",
       "1005620 2015-01  GE  1212     2          477               32           2.0   \n",
       "        2015-02  GE  1212     2          477               32           2.0   \n",
       "        2015-03  GE  1212     2          477               32           2.0   \n",
       "        2015-04  GE  1212     2          477               32           2.0   \n",
       "        2015-05  GE  1212     2          477               32           2.0   \n",
       "\n",
       "                 FTE_Enterprise  Profiling Sample_ID Noga_Enterprise  ...  \\\n",
       "OID     Date                                                          ...   \n",
       "1005620 2015-01       25.969999          0        Q3            4773  ...   \n",
       "        2015-02       25.969999          0        Q3            4773  ...   \n",
       "        2015-03       25.969999          0        Q3            4773  ...   \n",
       "        2015-04       25.969999          0        Q3            4773  ...   \n",
       "        2015-05       25.969999          0        Q3            4773  ...   \n",
       "\n",
       "                Split  SentFor  TOV  nb_modif  Year  Month  Lockdown  \\\n",
       "OID     Date                                                           \n",
       "1005620 2015-01     0      NaN  552         1  2015      1       0.0   \n",
       "        2015-02     0      NaN  554         1  2015      2       0.0   \n",
       "        2015-03     0      NaN  629         1  2015      3       0.0   \n",
       "        2015-04     0      NaN  546         1  2015      4       0.0   \n",
       "        2015-05     0      NaN  569         1  2015      5       0.0   \n",
       "\n",
       "                 TOV_lag1 TOV_lag2 TOV_lag12  \n",
       "OID     Date                                  \n",
       "1005620 2015-01     681.0    599.0     519.0  \n",
       "        2015-02     552.0    681.0     523.0  \n",
       "        2015-03     554.0    552.0     600.0  \n",
       "        2015-04     629.0    554.0     560.0  \n",
       "        2015-05     546.0    629.0     582.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining variable lists\n",
    "#ID = ['OID', 'Date']\n",
    "target = ['TOV']\n",
    "nom_vars = ['KT', 'Lang', 'Stratum_Noga', 'Sample_ID', 'Noga_Enterprise', 'Hist_Limit', 'Channel_ID']\n",
    "ord_vars = ['Stratum_Size']\n",
    "disc_vars = ['Year', 'Month']\n",
    "cont_vars = ['TOV_lag1', 'TOV_lag2', 'TOV_lag12', 'VAT', 'Empl_Enterprise', 'FTE_Enterprise', 'Empl_RT']\n",
    "flags = ['Profiling', 'Group', 'Split', 'Sample_1', 'Sample_2', 'Lockdown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df2020:  (143933, 24)\n",
      "df2019:  (126192, 24)\n"
     ]
    }
   ],
   "source": [
    "# Defining datasets\n",
    "\n",
    "# df2020: complete dataset\n",
    "df2020=resp_data[target+disc_vars+nom_vars+ord_vars+cont_vars+flags]\n",
    "\n",
    "# df2019: dataset without data from 2020\n",
    "df2019=resp_data[target+disc_vars+nom_vars+ord_vars+cont_vars+flags][resp_data['Year']<2020].copy()\n",
    "\n",
    "print('df2020: ', df2020.shape)\n",
    "print('df2019: ', df2019.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Defining Preprocessing Functions <a name=\"1.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating percentage of missing values\n",
    "def missing(df):\n",
    "    missing=pd.merge(df.isnull().sum().to_frame('nb_miss').rename_axis('Var').reset_index(),df.count().to_frame('non_miss').rename_axis('Var').reset_index())\n",
    "    missing[\"total\"]=missing[\"non_miss\"]+missing[\"nb_miss\"]\n",
    "    missing[\"miss_pct\"]=missing[\"nb_miss\"]/missing[\"total\"]*100\n",
    "    missing=missing[missing['miss_pct']>0]\n",
    "    \n",
    "    return missing.sort_values(by='miss_pct', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculation of median and max values\n",
    "cont_vars_median = []\n",
    "nom_vars_max = []\n",
    "ord_vars_max = []\n",
    "\n",
    "def calc_median(df):\n",
    "    \n",
    "    # (A) Calculate median of continuous and discrete variables\n",
    "    for c in cont_vars:\n",
    "        cont_vars_median.append(np.median(df[c].dropna()))\n",
    " \n",
    "    # (B) Calculate most frequent value of nominal and ordinal variables\n",
    "    for n in nom_vars:\n",
    "         nom_vars_max.append(df[n].value_counts().idxmax())\n",
    "  \n",
    "    for o in ord_vars:\n",
    "         ord_vars_max.append(df[o].value_counts().idxmax()) \n",
    "\n",
    "    #print('cont_vars_median:', cont_vars_median)\n",
    "    #print('nom_vars_max:', nom_vars_max)\n",
    "    #print('ord_vars_max:', ord_vars_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess(df):\n",
    "    # Work on a copy\n",
    "    df = df.copy()\n",
    "\n",
    "    # (A) Fill missing values\n",
    "            \n",
    "    # Replacing missing continuous variables with median from train set\n",
    "    for c in range (0,len(cont_vars)):\n",
    "         df.loc[(df[cont_vars[c]].isnull()), (cont_vars[c])] =  cont_vars_median[c]\n",
    "            \n",
    "    # Replacing missing nominal variables with most frequent value from train set\n",
    "    for n in range (0,len(nom_vars)):\n",
    "         df.loc[(df[nom_vars[n]].isnull()), (nom_vars[n])] =  nom_vars_max[n]\n",
    "  \n",
    "    # Replacing missing ordinal variables with most frequent value from train set\n",
    "    for o in range (0,len(ord_vars)):\n",
    "         df.loc[(df[ord_vars[o]].isnull()), (ord_vars[o])] =  ord_vars_max[o] \n",
    "\n",
    "    # (B) Encoding of ordinal variables \n",
    "      \n",
    "    # (C) Add new features\n",
    "    \n",
    "    # (D) One-hot encoding\n",
    "    df = pd.get_dummies(df, columns=nom_vars+disc_vars, drop_first=True)\n",
    "    \n",
    "    # (E) Apply log-transform\n",
    "    df[cont_vars] = np.log1p(df[cont_vars])\n",
    "\n",
    "    # (F) Drop superfluous variables\n",
    "    #df.drop(ID, axis=1, inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check equality of number and order of columns in train and test sets\n",
    "def check_cols(train,test):\n",
    "    # Work on a copy\n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "    print('Check: train.cols=',train.columns.shape,', test.cols=',test.columns.shape)  \n",
    "    \n",
    "    if train.columns.shape > test.columns.shape:\n",
    "        print('Case: train > test')\n",
    "        print('Missing columns:',set(list(train.columns.values.tolist()))-set(list(test.columns.values.tolist())))\n",
    "        # Reindex DataFrame test with columns from train and fill new columns with 0\n",
    "        train_reindexed = train\n",
    "        test_reindexed = test.reindex(columns=train.columns, fill_value=0)\n",
    "    else:\n",
    "        print('Case: train < test')\n",
    "        print('Missing columns:',set(list(test.columns.values.tolist()))-set(list(train.columns.values.tolist())))\n",
    "        # Reindex DataFrame train with columns from test and fill new columns with 0\n",
    "        train_reindexed = train.reindex(columns=test.columns, fill_value=0)\n",
    "        test_reindexed= test\n",
    "        \n",
    "    print('Result: train.shape=',train_reindexed.shape,', test.shape=',test_reindexed.shape)\n",
    "    return train_reindexed, test_reindexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Train/Test Split <a name=\"1.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame 2020: (100753, 24)\n",
      "Test DataFrame 2020: (43180, 24)\n",
      "Train DataFrame 2019: (88334, 24)\n",
      "Test DataFrame 2019: (37858, 24)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train/test sets\n",
    "train_df2020, test_df2020 = train_test_split(\n",
    "   df2020, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "train_df2019, test_df2019 = train_test_split(\n",
    "   df2019, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "print('Train DataFrame 2020:', train_df2020.shape)\n",
    "print('Test DataFrame 2020:', test_df2020.shape)\n",
    "print('Train DataFrame 2019:', train_df2019.shape)\n",
    "print('Test DataFrame 2019:', test_df2019.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting testsets for predictions\n",
    "test_df2020.to_csv(\"df2020_pred.csv\", encoding='utf-8', index=True)\n",
    "test_df2019.to_csv(\"df2019_pred.csv\", encoding='utf-8', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Cleaning / Feature Encoding <a name=\"1.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_encoding(train_df,test_df):\n",
    "    # Work on a copy\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    # Analyzing missing values\n",
    "    print('START feature encoding')\n",
    "    print('--- Missing values in train set before treatment:')\n",
    "    print(train_df.isnull().sum())\n",
    "    #print('---------------------------')\n",
    "    print('--- Missing values in test set before treatment:')\n",
    "    print(test_df.isnull().sum())   \n",
    "    print('---------------------------')\n",
    "    \n",
    "    # Calculating median and max values from train set    \n",
    "    calc_median(train_df)\n",
    "    \n",
    "    # Cleaning and encoding of train set\n",
    "    train_df_encoded=preprocess(train_df)   \n",
    "    \n",
    "    # Cleaning of test set and applying median and max values from train set\n",
    "    test_df_encoded=preprocess(test_df)\n",
    "    \n",
    "    # Checking if the number and order of columns in the test and train set are equal\n",
    "    (train_df_final,test_df_final)=check_cols(train_df_encoded, test_df_encoded)\n",
    "    \n",
    "    print('---------------------------') \n",
    "    print('--- Missing values in train set after treatment:',train_df_final.isnull().sum().sum())\n",
    "    print('--- Missing values in test set after treatment:',test_df_final.isnull().sum().sum())      \n",
    "    print('END feature encoding')\n",
    "    \n",
    "    return train_df_final, test_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START feature encoding\n",
      "--- Missing values in train set before treatment:\n",
      "TOV                  0\n",
      "Year                 0\n",
      "Month                0\n",
      "KT                   0\n",
      "Lang                 0\n",
      "Stratum_Noga        47\n",
      "Sample_ID            0\n",
      "Noga_Enterprise     47\n",
      "Hist_Limit           0\n",
      "Channel_ID          37\n",
      "Stratum_Size        47\n",
      "TOV_lag1             0\n",
      "TOV_lag2             0\n",
      "TOV_lag12            0\n",
      "VAT                332\n",
      "Empl_Enterprise      0\n",
      "FTE_Enterprise       0\n",
      "Empl_RT             71\n",
      "Profiling            0\n",
      "Group                0\n",
      "Split                0\n",
      "Sample_1             0\n",
      "Sample_2             0\n",
      "Lockdown             0\n",
      "dtype: int64\n",
      "--- Missing values in test set before treatment:\n",
      "TOV                  0\n",
      "Year                 0\n",
      "Month                0\n",
      "KT                   0\n",
      "Lang                 0\n",
      "Stratum_Noga        28\n",
      "Sample_ID            0\n",
      "Noga_Enterprise     28\n",
      "Hist_Limit           0\n",
      "Channel_ID          12\n",
      "Stratum_Size        28\n",
      "TOV_lag1             0\n",
      "TOV_lag2             0\n",
      "TOV_lag12            0\n",
      "VAT                154\n",
      "Empl_Enterprise      0\n",
      "FTE_Enterprise       0\n",
      "Empl_RT             33\n",
      "Profiling            0\n",
      "Group                0\n",
      "Split                0\n",
      "Sample_1             0\n",
      "Sample_2             0\n",
      "Lockdown             0\n",
      "dtype: int64\n",
      "---------------------------\n",
      "Check: train.cols= (167,) , test.cols= (168,)\n",
      "Case: train < test\n",
      "Missing columns: {'Noga_Enterprise_4639'}\n",
      "Result: train.shape= (100753, 168) , test.shape= (43180, 168)\n",
      "---------------------------\n",
      "--- Missing values in train set after treatment: 0\n",
      "--- Missing values in test set after treatment: 0\n",
      "END feature encoding\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning and feature encoding of df2020\n",
    "(train_df2020_final,test_df2020_final)=feat_encoding(train_df2020,test_df2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START feature encoding\n",
      "--- Missing values in train set before treatment:\n",
      "TOV                  0\n",
      "Year                 0\n",
      "Month                0\n",
      "KT                   0\n",
      "Lang                 0\n",
      "Stratum_Noga        46\n",
      "Sample_ID            0\n",
      "Noga_Enterprise     46\n",
      "Hist_Limit           0\n",
      "Channel_ID          23\n",
      "Stratum_Size        46\n",
      "TOV_lag1             0\n",
      "TOV_lag2             0\n",
      "TOV_lag12            0\n",
      "VAT                313\n",
      "Empl_Enterprise      0\n",
      "FTE_Enterprise       0\n",
      "Empl_RT             80\n",
      "Profiling            0\n",
      "Group                0\n",
      "Split                0\n",
      "Sample_1             0\n",
      "Sample_2             0\n",
      "Lockdown             0\n",
      "dtype: int64\n",
      "--- Missing values in test set before treatment:\n",
      "TOV                  0\n",
      "Year                 0\n",
      "Month                0\n",
      "KT                   0\n",
      "Lang                 0\n",
      "Stratum_Noga        17\n",
      "Sample_ID            0\n",
      "Noga_Enterprise     17\n",
      "Hist_Limit           0\n",
      "Channel_ID           9\n",
      "Stratum_Size        17\n",
      "TOV_lag1             0\n",
      "TOV_lag2             0\n",
      "TOV_lag12            0\n",
      "VAT                125\n",
      "Empl_Enterprise      0\n",
      "FTE_Enterprise       0\n",
      "Empl_RT             24\n",
      "Profiling            0\n",
      "Group                0\n",
      "Split                0\n",
      "Sample_1             0\n",
      "Sample_2             0\n",
      "Lockdown             0\n",
      "dtype: int64\n",
      "---------------------------\n",
      "Check: train.cols= (165,) , test.cols= (166,)\n",
      "Case: train < test\n",
      "Missing columns: {'Noga_Enterprise_4646'}\n",
      "Result: train.shape= (88334, 166) , test.shape= (37858, 166)\n",
      "---------------------------\n",
      "--- Missing values in train set after treatment: 0\n",
      "--- Missing values in test set after treatment: 0\n",
      "END feature encoding\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning and feature encoding of df2019\n",
    "(train_df2019_final,test_df2019_final)=feat_encoding(train_df2019,test_df2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Create X/y Data <a name=\"1.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models with root mean squared error (RMSE)\n",
    "def RMSE(y, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y-y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2020_tr: (100753, 167)\n",
      "X2020_te: (43180, 167)\n",
      "X2020_tr_rescaled: (100753, 167)\n",
      "X2020_te_rescaled: (43180, 167)\n"
     ]
    }
   ],
   "source": [
    "## Complete dataset ending 2020\n",
    "# Create X/y data\n",
    "X2020_tr = train_df2020_final.drop(columns=['TOV']).values\n",
    "y2020_tr = np.log1p(train_df2020_final.TOV).values\n",
    "\n",
    "X2020_te = test_df2020_final.drop(columns=['TOV']).values\n",
    "y2020_te = np.log1p(test_df2020_final.TOV).values\n",
    "\n",
    "# Standardize features\n",
    "scaler2020 = StandardScaler()\n",
    "X2020_tr_rescaled = scaler2020.fit_transform(X2020_tr)\n",
    "X2020_te_rescaled = scaler2020.transform(X2020_te)\n",
    "\n",
    "print('X2020_tr:', X2020_tr.shape)\n",
    "print('X2020_te:', X2020_te.shape)\n",
    "print('X2020_tr_rescaled:', X2020_tr_rescaled.shape)\n",
    "print('X2020_te_rescaled:', X2020_te_rescaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2019_tr: (88334, 165)\n",
      "X2019_te: (37858, 165)\n",
      "X2019_tr_rescaled: (88334, 165)\n",
      "X2019_te_rescaled: (37858, 165)\n"
     ]
    }
   ],
   "source": [
    "## Dataset ending 2019\n",
    "# Create X/y data\n",
    "X2019_tr = train_df2019_final.drop(columns=['TOV']).values\n",
    "y2019_tr = np.log1p(train_df2019_final.TOV).values\n",
    "\n",
    "X2019_te = test_df2019_final.drop(columns=['TOV']).values\n",
    "y2019_te = np.log1p(test_df2019_final.TOV).values\n",
    "\n",
    "# Standardize features\n",
    "scaler2019 = StandardScaler()\n",
    "X2019_tr_rescaled = scaler2019.fit_transform(X2019_tr)\n",
    "X2019_te_rescaled = scaler2019.transform(X2019_te)\n",
    "\n",
    "print('X2019_tr:', X2019_tr.shape)\n",
    "print('X2019_te:', X2019_te.shape)\n",
    "print('X2019_tr_rescaled:', X2019_tr_rescaled.shape)\n",
    "print('X2019_te_rescaled:', X2019_te_rescaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features into .npz files\n",
    "np.savez('train_data_2020.npz', features=X2020_tr, targets=y2020_tr)\n",
    "np.savez('train_data_rescaled_2020.npz', features=X2020_tr_rescaled, targets=y2020_tr)\n",
    "np.savez('test_data_2020.npz', features=X2020_te, targets=y2020_te)\n",
    "np.savez('test_data_rescaled_2020.npz', features=X2020_te_rescaled, targets=y2020_te)\n",
    "\n",
    "np.savez('train_data_2019.npz', features=X2019_tr, targets=y2019_tr)\n",
    "np.savez('train_data_rescaled_2019.npz', features=X2019_tr_rescaled, targets=y2019_tr)\n",
    "np.savez('test_data_2019.npz', features=X2019_te, targets=y2019_te)\n",
    "np.savez('test_data_rescaled_2019.npz', features=X2019_te_rescaled, targets=y2019_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Create Baseline <a name=\"1.5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turnover of the same enterprise one year before is set as the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>3145.044</td>\n",
       "      <td>40103.069</td>\n",
       "      <td>15.322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model       MAE       RMSE     MSE\n",
       "0  Baseline  3145.044  40103.069  15.322"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline 2020: turnover one year before\n",
    "y2020_te_baseline = np.log1p(test_df2020_final.TOV_lag12).values\n",
    "\n",
    "# Save baseline data into .npz file\n",
    "np.savez('y2020_te_baseline.npz', targets=y2020_te_baseline)\n",
    "\n",
    "# Calculate baseline accuracy\n",
    "mae_baseline2020 = MAE(np.expm1(y2020_te), np.expm1(y2020_te_baseline))\n",
    "rmse_baseline2020=RMSE(np.expm1(y2020_te), np.expm1(y2020_te_baseline))\n",
    "mse_baseline2020 = MSE(y2020_te, y2020_te_baseline)\n",
    "\n",
    "# Export baseline accuracy\n",
    "baseline2020=pd.DataFrame([['Baseline', '{:.3f}'.format(mae_baseline2020), '{:.3f}'.format(rmse_baseline2020), '{:.3f}'.format(mse_baseline2020)]],\n",
    "                 columns=['Model', 'MAE', 'RMSE', 'MSE'])\n",
    "baseline2020.to_csv(\"baseline2020.csv\", encoding='utf-8', index=False)\n",
    "baseline2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>2956.581</td>\n",
       "      <td>38434.627</td>\n",
       "      <td>15.130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model       MAE       RMSE     MSE\n",
       "0  Baseline  2956.581  38434.627  15.130"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline 2019: turnover one year before\n",
    "y2019_te_baseline = np.log1p(test_df2019_final.TOV_lag12).values\n",
    "\n",
    "# Save baseline data into .npz file\n",
    "np.savez('y2019_te_baseline.npz', targets=y2019_te_baseline)\n",
    "\n",
    "# Calculate baseline accuracy\n",
    "mae_baseline2019 = MAE(np.expm1(y2019_te), np.expm1(y2019_te_baseline))\n",
    "rmse_baseline2019=RMSE(np.expm1(y2019_te), np.expm1(y2019_te_baseline))\n",
    "mse_baseline2019 = MSE(y2019_te, y2019_te_baseline)\n",
    "\n",
    "# Export baseline accuracy\n",
    "baseline2019=pd.DataFrame([['Baseline', '{:.3f}'.format(mae_baseline2019), '{:.3f}'.format(rmse_baseline2019), '{:.3f}'.format(mse_baseline2019)]],\n",
    "                 columns=['Model', 'MAE', 'RMSE', 'MSE'])\n",
    "baseline2019.to_csv(\"baseline2019.csv\", encoding='utf-8', index=False)\n",
    "baseline2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
